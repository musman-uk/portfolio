## 📋 Support Logs

Support Logs is a mock technical support dashboard. It demonstrates how structured issue tracking communicates clearly, builds trust, and reduces friction. Each log captures the **report, environment, status, diagnosis, and resolution** in a format that mirrors real support workflows.

---

## 📓 Logbook

### Log 1: Data Export Corruption (ID: SL‑001, Opened: 2025‑09‑14)
💼 **Reported By:** Finance Team  
🖥️ **Environment:** Web App v3.4 · Windows 11 · Chrome 118  
✔️ **Status:** Resolved  

- **Summary:** During month‑end reporting, CSV exports from the financial dashboard produced malformed files, with missing headers and shifted columns.  
- **Impact:** The Finance Team faced significant disruption at a critical reporting period, forcing manual reconciliation of sensitive data. This not only created stress and overtime for staff but also introduced the risk of errors in regulatory submissions.  
- **Diagnosis:** Root cause analysis traced the issue to a recent update in the CSV serialization library, which mishandled UTF‑8 characters and corrupted field alignment.  
- **Resolution:** The team rolled back to a stable library version, implemented regression tests for export formatting, and added monitoring to ensure future updates do not silently break reporting workflows.  

→ [View Full Log](logs/log-1-data-export/ISSUE.md)

---

### Log 2: Notification Delivery Delays (ID: SL‑002, Opened: 2025‑09‑22)
🎧 **Reported By:** Customer Support  
📱 **Environment:** Mobile App v2.1 · iOS 17  
✔️ **Status:** Resolved  

- **Summary:** Push notifications for critical account alerts were delayed by up to 15 minutes, undermining the reliability of time‑sensitive communication.  
- **Impact:** Customers missed urgent updates, such as payment confirmations and security alerts, leading to frustration, increased support calls, and a temporary loss of trust in the app’s responsiveness. Support agents reported a surge in tickets, adding pressure to frontline teams.  
- **Diagnosis:** Investigation revealed a queue backlog caused by a misconfigured retry policy in the message broker, which compounded under peak load.  
- **Resolution:** Engineers adjusted retry thresholds, scaled the broker cluster, and introduced latency monitoring with proactive alerts, ensuring customers receive critical notifications promptly and restoring confidence in the service.  

→ [View Full Log](logs/log-2-notification-delays/ISSUE.md)


### Log 3: Authentication Timeout (ID: SL‑003, Planned)
🔍 **Reported By:** Internal QA  
🌐 **Environment:** API Gateway · Staging Cluster  
✔️ **Status:** Planned  

- **Summary:** Users intermittently experience timeouts during login under high load.  
- **Impact:** Authentication failures block access to core services, creating frustration and potential security concerns.  
- **Planned Action:** Stress‑test gateway under simulated peak load, optimise session handling, and add retry logic.  

---

### Log 4: Rate‑Limit Misconfiguration (ID: SL‑004, Planned)
🗃️ **Reported By:** Developer Tools Team  
🔌 **Environment:** 3rd‑Party API Integration  
✔️ **Status:** Planned  

- **Summary:** API requests are being throttled prematurely due to incorrect rate‑limit headers.  
- **Impact:** Downstream services fail to fetch required data, causing degraded user experience.  
- **Planned Action:** Align rate‑limit configs with provider documentation, add monitoring for quota thresholds, and implement graceful fallback.  

---

## 🗺️ Roadmap

- Add Log 5: Analytics Accuracy Issues (mismatched metrics across dashboards)  
- Add Log 6: Multi‑Region Deployment Latency (failover testing)  
- Introduce severity levels (🟢🟡🔴) and timeline view for issue lifecycle
